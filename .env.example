# AIComplianceGuard Environment Configuration

# Application
APP_NAME=AIComplianceGuard
APP_VERSION=1.0.0
ENVIRONMENT=development

# Backend API
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
API_PREFIX=/api/v1

# Frontend
REACT_APP_API_URL=http://localhost:8000/api/v1
REACT_APP_NAME=AIComplianceGuard

# Security
SECRET_KEY=your-secret-key-here-change-in-production
AES_ENCRYPTION_KEY=your-32-byte-aes-key-here-change-in-production
JWT_SECRET=your-jwt-secret-here-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Firebase Configuration
FIREBASE_API_KEY=your-firebase-api-key
FIREBASE_AUTH_DOMAIN=your-project.firebaseapp.com
FIREBASE_PROJECT_ID=your-project-id
FIREBASE_STORAGE_BUCKET=your-project.appspot.com
FIREBASE_MESSAGING_SENDER_ID=your-sender-id
FIREBASE_APP_ID=your-app-id
FIREBASE_MEASUREMENT_ID=your-measurement-id

# Firebase Admin SDK (for backend)
FIREBASE_CREDENTIALS_PATH=./firebase-credentials.json

# AI/ML Configuration
MODEL_CACHE_DIR=./data/models
USE_GPU=false
MAX_DOCUMENT_SIZE_MB=10
SUPPORTED_FORMATS=pdf,docx

# LLM Provider: "gemini", "llama_cpp", "transformers", or "none"
LLM_PROVIDER=gemini

# Gemini Configuration (recommended - cloud API)
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL=gemini-2.0-flash
GEMINI_MAX_TOKENS=2048
GEMINI_TEMPERATURE=0.3

# Llama Configuration (alternative - local model)
# LLAMA_MODEL_PATH=
# LLAMA_MODEL_REPO=TheBloke/Llama-2-7B-Chat-GGUF
# LLAMA_MODEL_FILE=llama-2-7b-chat.Q4_K_M.gguf

# Document Processing
TEMP_UPLOAD_DIR=./temp_uploads
AUTO_DELETE_AFTER_MINUTES=5

# Compliance Frameworks
FRAMEWORKS_DATA_DIR=./data/frameworks

# Audit Prediction Model
AUDIT_MODEL_PATH=./data/models/audit_predictor.pkl
AUDIT_SCALER_PATH=./data/models/audit_scaler.pkl

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/aicomplianceguard.log

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Rate Limiting
RATE_LIMIT_PER_MINUTE=10

# Database
DB_ENCRYPTION_ENABLED=true

# Monitoring (Optional)
SENTRY_DSN=
ANALYTICS_ENABLED=false
